# Текст выступления для доклада

[Title page]
У каждого из нас есть проблемы,...
 проблемы, которые можно решить с помощью ML!
Однажды, 1 января я проснулся и понял, что ML это будущее, об этом и не только, мы с вами сегодня и поговорим.
Важный акцент, который я постараюсь выделить в данном докладе - то, что ML - это легче, чем кажется)

[Cover page]
Так, в общем и в целом всееем привет!
Доклад будет направлен по большей части на обозрение пременения artificial intelligence & machine learning как инструмента для решения бизнес и возможно некоторых повседневных задач.

[Page about me]
И так, пара слов обо мне, я Старший Инженер Разработчик в компании Opensoft.
Занимаемся product разработкой для разного рода компаний занимающихся печатной продукцией и всеми теми вещами, которые так или иначе связаны с этим.
Однако, для меня машинное обучение не более чем хобби и развлечение, изучением которого я занимаюсь в рамках своего свободного времени.

[первый мем]
Здесь меня можно увидеть справа)

[Page about the plan]
Наш план будет такой:
- сперва мы дадим поверхностное определение понятие того, чем верхнеуровнего по сути своей является AI
- взглянем на некоторые бизнес задачи, которые решает машинное обучение
- затронем некоторые теоретические основы machine learning с точки зрения high level overview 
- посмотрим реализацию простейшего примера, который решает задачу по оценке комментариев на продукт с точки зрения конечных пользователей
- подытожим списком задач под которые машинное обучение будет весьма кстати, а в которых скорее всего будет крайне неэффективным
- какие задачи на сегодняшний день решает машинное обучение
- выводы

[что такое ML]
Что ж, теперь взглянем на то, как можно интерпретировать данное понятие...
Первоосновой основой ML можно назвать 3 основные вещи:
Данные, Алгоритмы и Признаки

__Данные__ Хотим определять спам — нужны примеры спам-писем, предсказывать курс акций — нужна история цен, узнать интересы пользователя — нужны его лайки или посты. Данных нужно как можно больше. Десятки тысяч примеров — это самый злой минимум для отчаянных.


Данные собирают как могут. Кто-то вручную — получается дольше, меньше, зато без ошибок. Кто-то автоматически — просто сливает машине всё, что нашлось, и верит в лучшее. Самые хитрые, типа гугла, используют своих же пользователей для бесплатной разметки. Вспомните ReCaptcha, которая иногда требует «найти на фотографии все дорожные знаки» — это оно и есть.

За хорошими наборами данных (датасетами) идёт большая охота. Крупные компании, бывает, раскрывают свои алгоритмы, но датасеты — крайне редко.

__Признаки__ Мы называем их фичами (features), так что ненавистникам англицизмов придётся страдать. Фичи, свойства, характеристики, признаки — ими могут быть пробег автомобиля, пол пользователя, цена акций, даже счетчик частоты появления слова в тексте может быть фичей.

Машина должна знать, на что ей конкретно смотреть. Хорошо, когда данные просто лежат в табличках — названия их колонок и есть фичи. А если у нас сто гигабайт картинок с котами? Когда признаков много, модель работает медленно и неэффективно. Зачастую отбор правильных фич занимает больше времени, чем всё остальное обучение. Но бывают и обратные ситуации, когда кожаный мешок сам решает отобрать только «правильные» на его взгляд признаки и вносит в модель субъективность — она начинает дико врать.

__Алгоритм__ Одну задачу можно решить разными методами примерно всегда. От выбора метода зависит точность, скорость работы и размер готовой модели. Но есть один нюанс: если данные говно, даже самый лучший алгоритм не поможет. Не зацикливайтесь на процентах, лучше соберите побольше данных.

На стыке областей мы получаем: науку изучающую данные, датамайнинг и классическое программирование,
которов вкупе дает нам __МАШИННОЕ ОБУЧЕНИЕ__


[Где оно нужно?]

Теперь посмотрим, где это может оказаться полезным...

По сути своей всё то, что мы делаем как живые существа, это то, что пытаемся адаприроваться 
к изменяющимся условиям окружающей среды, используя наши органы чувств.

некоторыми из этих вещей являются распознавание и генерация
Текста, картинок, видео и аудио


[Недостатки]
Теперь поговорим о недостатках

1. Сложные сценарии - ничто иное, как недостаток наших знаний и других ресурсов, чтобы воплотить наши идеи в жизнь.
   все говорят о скайнет, но никто еще его пока не изобрел
2. Недостаток данных, особенно важно, когда нам нехватает качественных данных из-за чего нам крайне проблематичным
может оказаться какое либо обучение. Если человеку не предоставить никакой информации, он с существенно меньшей вероятностью сможет заполучить ее.
3. Примером 3-му пункту может служить медицинская сфера, допустим, когда нам важно обосновать наше решение 
по выставленному диагнозу, если с этим возникают проблемы, то может оказаться крайне проблематичным
внедрение подобных технологий
4. Если задачу нужно решить 1, 2 раза, либо требуется существенно меньше ресурсов для ее воплощения,
то машинное обучение может оказаться здесь лишним
5. эта проблема была если и будет еще довольно долго, пока машины не научатся делать все то, что умеет обычный человек


[из чего состоит ML]
теперь поговорим о его внутреннем устройстве)

Однажды в одном хипстерском издании я видел статью под заголовком «Заменят ли нейросети машинное обучение». Пиарщики в своих пресс-релизах обзывают «искусственным интеллектом» любую линейную регрессию, с которой уже дети во дворе играют. Объясняю разницу на картинке, раз и навсегда.

__Искусственный интеллект__ — название всей области, как биология или химия.

__Машинное обучение__ — это раздел искусственного интеллекта. Важный, но не единственный.

__Нейросети__ — один из видов машинного обучения. Популярный, но есть и другие, не хуже.

__Глубокое обучение__ — архитектура нейросетей, один из подходов к их построению и обучению. На практике сегодня мало кто отличает, где глубокие нейросети, а где не очень. Говорят название конкретной сети и всё.

[типы обучения]
взглянем на это под ракурсом видов обучения
Для краткости и простоты изложения я остановлюсь лишь на некоторых из них.

__Обуче́ние с учи́телем__ — один из способов машинного обучения, в ходе которого испытуемая система принудительно обучается с помощью примеров «стимул-реакция». 

__Обучение без учителя__ (самообучение, спонтанное обучение, англ. Unsupervised learning) — один из способов машинного обучения, при котором испытуемая система спонтанно обучается выполнять поставленную задачу без вмешательства со стороны экспериментатора. 

__Обучение с подкреплением__ (англ. reinforcement learning) — один из способов машинного обучения, в ходе которого испытуемая система (агент) обучается, взаимодействуя с некоторой средой.

__Глубокое обучение__ — совокупность методов машинного обучения (с учителем, с частичным привлечением учителя, без учителя, с подкреплением), основанных на обучении представлениям, а не специализированным алгоритмам под конкретные задачи.

[ML инструменты]
Теперь поговорим о том, как и с помощью чего это можно воплощать в жизнь.

Инструменты, как на JavaScript, так и на Пайтон можно подразделить на 2 отдельные группы
Фреймворки, на которых пишем нейронки, и то с помощью чего мы может конвертировать их в разные форматы
в зависимости от ситууции и задач

Так или иначе аналоги первоисходных Python библиотек можно практически найти наверняка и в javascript
добавляя окончание JS

[Анализ настроений]

Теперь посмотрим, как всё это выглядит на практике

Анализ настроений - есть ничто иное как подраздел группы различных исследовании связанный с "Анализом тональности текста"

По сути являет собой механизм по выявлению и определению эмоционально окрашенных фрагментов текста и 
на основе этого он определяет является ли данное сообщение, позитивный, нейтральным или негативным.

[архитекруты нейронок]
с точки зрения выбора архитектуры есть 3 основных кандидата это
рекуррентная нейронная сеть, где скрытые слои нейронов имеют связи в предшествующими соседями и иногда на 
самих себя, тем самым мы получаем эффект короткой пямяти, однако на деле этот вариант пригоден не более
чем на поиграться.

остаются 2 типа нейронок GRU - эта архитектура хоть и хороша в плане быстрого запоминания информации, 
однако не пригодна для хранения длинных цепочек действий

LSTM - уже имеет ячейки, в которых встроена дополнительная память тем самым
информация от N предыдущих нейронов также оседает и в последнем, тем самым получая высокое 
качество обработки входного сигнала.
Ее минусом является то, что через 20, 30, 100 элементов последовательности она начинает забывать
и постепенно теряет контекст того, что было в самом начале.


Чтож теперь посмотрим на демо.

[демо]

в рамках этого демо мы можем видеть то, что на основе входного текста
нейронке удалось выявить те фрагменты, которые носят позитивный окрас, получая тем самым
конечный результат в виде 74% того, что это является положительным комментарием.

По аналогии с положительным LSTM также может видеть и негативный окрас

Тут более сложный пример, где она выделяет позитивные наряду и с негативными моментами, вычисляя итоговую
оценку положительности предоставленного текста. 


[бизнес значимость]
теперь посмотрим на это с точки зрения бизнеса

[Где можно применять]
на деле анализ настроений можно применять в 3 аспектах

__управление репутацией__ - когда вместо людей ответственных за чтение новостей и прочих ресурсов
мы используем нейронку, которая просто напросто выдает результат того, что происходит на 
конкурирующем рынке

__клиентская поддержка__ - чат боты, автоответчики все то, что может взаимодействовать с пользователем
в рамках коммуникаций

__мониторинг конкурентов__ - чем-то схож с первым однако мы исследуем то, как дела идут у наших соперников
выявляя их сильные и слабые стороны

[итоги]
что ж история оказалась весьма интригующей, особенно если вглядываться детальней,
чем больше мы узнаем, тем меньшее мы знаем, если нам кажется, что мы знаем все, возможно, мы нашли тупик.
Индустрия автоматизации продолжает железной поступью двигаться вперед, и только мы определяем то, 
будем ли ее возглавлять или окажемся в подчинении у нее.

[Спасибо]

Всем спасибо!
Вопросы?

























